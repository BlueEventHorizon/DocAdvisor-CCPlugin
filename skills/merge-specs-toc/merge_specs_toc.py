#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
specs_toc.yaml ãƒãƒ¼ã‚¸ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ç‰ˆï¼‰

specs/.toc_work/*.yaml ã‹ã‚‰å…¨ã‚¨ãƒ³ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿ã€
_meta ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é™¤å»ã—ã¦ãƒãƒ¼ã‚¸ã—ã€specs/specs_toc.yaml ã‚’ç”Ÿæˆã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 merge_specs_toc.py [--cleanup] [--mode full|incremental]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --cleanup   ãƒãƒ¼ã‚¸æˆåŠŸå¾Œã« .toc_work/ ã‚’å‰Šé™¤
    --mode      fullï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰: æ–°è¦ç”Ÿæˆã€incremental: å·®åˆ†ãƒãƒ¼ã‚¸
"""

import sys
import re
from datetime import datetime, timezone
from pathlib import Path

# å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
COMMON_DIR = Path(__file__).parent.parent / "toc-common"
sys.path.insert(0, str(COMMON_DIR))

from toc_utils import (
    get_project_root,
    load_config,
    load_entry_file,
    yaml_escape,
    backup_existing_file,
    load_checksums,
    cleanup_work_dir,
    should_exclude,
    extract_id_from_filename,
)

# è¨­å®šèª­ã¿è¾¼ã¿
CONFIG = load_config('specs')
PROJECT_ROOT = get_project_root()
SPECS_DIR = PROJECT_ROOT / CONFIG.get('root_dir', 'specs').rstrip('/')
TOC_WORK_DIR = SPECS_DIR / CONFIG.get('work_dir', '.toc_work').rstrip('/')
OUTPUT_FILE = SPECS_DIR / CONFIG.get('toc_file', 'specs_toc.yaml')
CHECKSUMS_FILE = SPECS_DIR / CONFIG.get('checksums_file', '.toc_checksums.yaml')
OUTPUT_CONFIG = CONFIG.get('output', {})
PATTERNS_CONFIG = CONFIG.get('patterns', {})
TARGET_DIRS = PATTERNS_CONFIG.get('target_dirs', ['requirements', 'design'])
EXCLUDE_PATTERNS = PATTERNS_CONFIG.get('exclude', ['.toc_work', '.toc_checksums.yaml', 'specs_toc.yaml', 'reference', '/info/'])


def extract_feature_from_path(source_file):
    """ãƒ‘ã‚¹ã‹ã‚‰ Featureå ã‚’æŠ½å‡º"""
    # main/requirements/... â†’ main
    parts = source_file.split('/')
    if len(parts) >= 1:
        return parts[0]
    return 'unknown'


def write_yaml_output(features_dict, specs, designs, output_path):
    """
    YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›

    Returns:
        bool: æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    lines = []

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ
    header_comment = OUTPUT_CONFIG.get('header_comment', 'specs-advisor Subagentç”¨ è¦ä»¶å®šç¾©æ›¸ãƒ»è¨­è¨ˆæ›¸æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')
    metadata_name = OUTPUT_CONFIG.get('metadata_name', 'è¦ä»¶å®šç¾©æ›¸ãƒ»è¨­è¨ˆæ›¸æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')

    lines.append("# specs/specs_toc.yaml")
    lines.append(f"# {header_comment}")
    lines.append("")

    lines.append("metadata:")
    lines.append(f"  name: {metadata_name}")
    lines.append(f"  generated_at: {datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')}")
    lines.append(f"  file_count: {len(specs) + len(designs)}")
    lines.append("")

    # features ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    lines.append("features:")
    for name, info in sorted(features_dict.items()):
        lines.append(f"  - name: {name}")
        lines.append(f"    status: {info.get('status', 'å®Œäº†')}")
        lines.append(f"    directory: {name}/")
        lines.append(f"    description: {info.get('description', f'{name} æ©Ÿèƒ½')}")
    lines.append("")

    # specs ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    lines.append("specs:")
    for doc_id, entry in sorted(specs.items()):
        lines.append(f"  {doc_id}:")
        for key in ['feature', 'category', 'title', 'summary']:
            if key in entry:
                lines.append(f"    {key}: {yaml_escape(entry[key])}")
        if 'keywords' in entry and entry['keywords']:
            lines.append("    keywords:")
            for kw in entry['keywords']:
                lines.append(f"      - {yaml_escape(kw)}")
        if 'file' in entry:
            lines.append(f"    file: {entry['file']}")
    lines.append("")

    # designs ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    lines.append("designs:")
    for doc_id, entry in sorted(designs.items()):
        lines.append(f"  {doc_id}:")
        for key in ['feature', 'category', 'layer', 'title', 'summary']:
            if key in entry and entry[key]:
                lines.append(f"    {key}: {yaml_escape(entry[key])}")
        if 'keywords' in entry and entry['keywords']:
            lines.append("    keywords:")
            for kw in entry['keywords']:
                lines.append(f"      - {yaml_escape(kw)}")
        if 'file' in entry:
            lines.append(f"    file: {entry['file']}")

    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines) + '\n')
        return True
    except (IOError, OSError, PermissionError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å¤±æ•—: {output_path} - {e}")
        return False


def load_existing_toc(toc_path):
    """æ—¢å­˜ã® specs_toc.yaml ã‚’èª­ã¿è¾¼ã¿"""
    if not toc_path.exists():
        return {}, {}, {}

    with open(toc_path, 'r', encoding='utf-8') as f:
        content = f.read()

    features = {}
    specs = {}
    designs = {}
    current_section = None
    current_id = None
    current_entry = {}
    current_list = None

    for line in content.split('\n'):
        stripped = line.strip()

        if stripped.startswith('#') or not stripped:
            continue

        if stripped == 'features:':
            current_section = 'features'
            continue
        elif stripped == 'specs:':
            current_section = 'specs'
            continue
        elif stripped == 'designs:':
            current_section = 'designs'
            continue
        elif stripped.startswith('metadata:'):
            current_section = 'metadata'
            continue

        if current_section == 'features' and stripped.startswith('- name:'):
            name = stripped.split(':', 1)[1].strip()
            features[name] = {'status': 'å®Œäº†', 'description': f'{name} æ©Ÿèƒ½'}
        elif current_section == 'features' and ':' in stripped:
            key, _, val = stripped.partition(':')
            key = key.strip()
            val = val.strip().strip('"\'')
            if features:
                last_feature = list(features.keys())[-1]
                features[last_feature][key] = val

        elif current_section in ('specs', 'designs'):
            if re.match(r'^[A-Z]+-\d+:', stripped):
                if current_id and current_entry:
                    if current_section == 'specs':
                        specs[current_id] = current_entry
                    else:
                        designs[current_id] = current_entry
                current_id = stripped.rstrip(':')
                current_entry = {}
                current_list = None
            elif line.startswith('    ') and ':' in stripped and not stripped.startswith('-'):
                if current_id:
                    key, _, val = stripped.partition(':')
                    key = key.strip()
                    val = val.strip().strip('"\'')
                    if val:
                        current_entry[key] = val
                    else:
                        current_list = []
                        current_entry[key] = current_list
            elif stripped.startswith('- ') and current_list is not None:
                item = stripped[2:].strip().strip('"\'')
                current_list.append(item)

    if current_id and current_entry:
        if current_section == 'specs':
            specs[current_id] = current_entry
        else:
            designs[current_id] = current_entry

    return features, specs, designs


def is_target_dir(filepath):
    """å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    rel_path = str(filepath.relative_to(SPECS_DIR))
    parts = rel_path.split('/')
    if len(parts) >= 2:
        return parts[1] in TARGET_DIRS
    return False


def get_existing_files():
    """ç¾åœ¨å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    files = set()
    for filepath in SPECS_DIR.rglob("*.md"):
        if should_exclude(filepath, SPECS_DIR, EXCLUDE_PATTERNS):
            continue
        if not is_target_dir(filepath):
            continue
        rel_path = str(filepath.relative_to(SPECS_DIR))
        files.add(rel_path)
    return files


def remove_empty_features(features_dict, specs, designs):
    """ã‚¨ãƒ³ãƒˆãƒªã®ãªã„ feature ã‚’å‰Šé™¤"""
    used_features = set()
    for entry in specs.values():
        used_features.add(entry.get('feature'))
    for entry in designs.values():
        used_features.add(entry.get('feature'))

    removed = []
    result = {}
    for name, info in features_dict.items():
        if name in used_features:
            result[name] = info
        else:
            removed.append(name)

    if removed:
        for name in removed:
            print(f"  ğŸ—‘ ç©º feature å‰Šé™¤: {name}")

    return result


def delete_only_mode():
    """å‰Šé™¤ã®ã¿ãƒ¢ãƒ¼ãƒ‰: .toc_work/ ãªã—ã§å‰Šé™¤ã‚’åæ˜ """
    print("ãƒ¢ãƒ¼ãƒ‰: delete-onlyï¼ˆå‰Šé™¤ã®ã¿ï¼‰")

    if not OUTPUT_FILE.exists():
        print("ã‚¨ãƒ©ãƒ¼: specs_toc.yaml ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return False

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_existing_file(OUTPUT_FILE)

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    features_dict, specs, designs = load_existing_toc(OUTPUT_FILE)

    # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ã«ã‚ã‚‹ãŒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
    checksum_files = load_checksums(CHECKSUMS_FILE)
    existing_files = get_existing_files()
    deleted_files = checksum_files - existing_files

    if not deleted_files:
        print("å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return True

    deleted_count = 0
    for del_file in deleted_files:
        del_id = extract_id_from_filename(del_file)
        if del_id:
            if del_id in specs:
                del specs[del_id]
                print(f"  ğŸ—‘ å‰Šé™¤: {del_id}")
                deleted_count += 1
            if del_id in designs:
                del designs[del_id]
                print(f"  ğŸ—‘ å‰Šé™¤: {del_id}")
                deleted_count += 1

    if deleted_count == 0:
        print("å‰Šé™¤å¯¾è±¡ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆIDãŒæŠ½å‡ºã§ããªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å¯èƒ½æ€§ï¼‰")
        return True

    # ç©º feature ã‚’å‰Šé™¤
    features_dict = remove_empty_features(features_dict, specs, designs)

    if not write_yaml_output(features_dict, specs, designs, OUTPUT_FILE):
        return False

    print(f"\nâœ… å‰Šé™¤å®Œäº†: {deleted_count}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤")
    return True


def merge_toc_files(mode='full'):
    yaml_files = sorted(TOC_WORK_DIR.glob("*.yaml"))

    if not yaml_files:
        print(f"ã‚¨ãƒ©ãƒ¼: {TOC_WORK_DIR} ã«YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(yaml_files)} ä»¶")
    print(f"ãƒ¢ãƒ¼ãƒ‰: {mode}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰å…±é€šï¼‰
    backup_existing_file(OUTPUT_FILE)

    # incremental ãƒ¢ãƒ¼ãƒ‰ã§ã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    if mode == 'incremental':
        features_dict, specs, designs = load_existing_toc(OUTPUT_FILE)
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ã«ã‚ã‚‹ãŒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
        checksum_files = load_checksums(CHECKSUMS_FILE)
        existing_files = get_existing_files()
        deleted_files = checksum_files - existing_files
        for del_file in deleted_files:
            del_id = extract_id_from_filename(del_file)
            if del_id:
                if del_id in specs:
                    del specs[del_id]
                    print(f"  ğŸ—‘ å‰Šé™¤: {del_id}")
                if del_id in designs:
                    del designs[del_id]
                    print(f"  ğŸ—‘ å‰Šé™¤: {del_id}")
    else:
        features_dict = {}
        specs = {}
        designs = {}

    errors = []

    for filepath in yaml_files:
        filename = filepath.name
        try:
            meta, entry = load_entry_file(filepath)
            source_file = meta.get('source_file')
            status = meta.get('status')
            doc_type = meta.get('doc_type')

            if not source_file:
                errors.append(f"{filename}: source_file ãŒå–å¾—ã§ããªã„")
                continue

            if status != 'completed':
                errors.append(f"{filename}: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ completed ã§ã¯ãªã„ï¼ˆ{status}ï¼‰")
                continue

            doc_id = entry.get('id')
            if not doc_id:
                errors.append(f"{filename}: id ãŒå–å¾—ã§ããªã„")
                continue

            # FeatureæŠ½å‡º
            feature = entry.get('feature') or extract_feature_from_path(source_file)
            entry['feature'] = feature

            # file ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®š
            entry['file'] = source_file

            # featuresè¾æ›¸ã«è¿½åŠ 
            if feature not in features_dict:
                features_dict[feature] = {'status': 'å®Œäº†', 'description': f'{feature} æ©Ÿèƒ½'}

            # doc_type ã§æŒ¯ã‚Šåˆ†ã‘
            if doc_type == 'design':
                designs[doc_id] = entry
                print(f"  âœ“ {doc_id} â†’ designs")
            else:
                specs[doc_id] = entry
                print(f"  âœ“ {doc_id} â†’ specs")

        except Exception as e:
            errors.append(f"{filename}: {e}")

    if errors:
        print("\nè­¦å‘Š:")
        for err in errors:
            print(f"  - {err}")

    if not specs and not designs:
        print("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")
        return False

    # ç©º feature ã‚’å‰Šé™¤
    features_dict = remove_empty_features(features_dict, specs, designs)

    if not write_yaml_output(features_dict, specs, designs, OUTPUT_FILE):
        return False

    print(f"\nâœ… ç”Ÿæˆå®Œäº†: {OUTPUT_FILE}")
    print(f"   - specs: {len(specs)}")
    print(f"   - designs: {len(designs)}")
    print(f"   - features: {len(features_dict)}")

    return True


def main():
    cleanup = '--cleanup' in sys.argv
    delete_only = '--delete-only' in sys.argv
    mode = 'full'
    if '--mode' in sys.argv:
        idx = sys.argv.index('--mode')
        if idx + 1 < len(sys.argv):
            mode = sys.argv[idx + 1]

    print("=" * 50)
    print("specs_toc.yaml ãƒãƒ¼ã‚¸ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 50)

    if delete_only:
        success = delete_only_mode()
    else:
        success = merge_toc_files(mode)

    if success and cleanup:
        cleanup_work_dir(TOC_WORK_DIR)

    return 0 if success else 1


if __name__ == '__main__':
    sys.exit(main())
